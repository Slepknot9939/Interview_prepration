# Interview_prepration

# Natural Language Processing
1) what is NLP?<br>
Answer:- Natural Language Processing is a field of computer science that deals with communication between computer systems and humans.
        e.g. Chatbot and google translator
        
2)  What are stop words?<br><br>
Answer:- Stop words are said to be useless data for a search engine.There are stop words such as was, were, is, am, the, a, an, how, why, and many more.In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.

3) What is NLTK?<br>
Answer:- NLTK is a Python library, which stands for Natural Language Toolkit. We use NLTK to process data in human spoken languages. NLTK allows us to apply techniques such as parsing, tokenization, lemmatization, stemming, and more to understand natural languages.

      A few of the libraries of the NLTK package that we often use in NLP are:<br>

      SequentialBackoffTagger<br>
      DefaultTagger<br>
      UnigramTagger<br>
      treebank<br>
      wordnet<br>
      FreqDist<br>
      patterns<br>
      RegexpTagger<br>
      backoff_tagger<br>
      UnigramTagger, BigramTagger, and TrigramTagger<br>

4)  What is Syntactic Analysis?<br>
Answer:-Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence.<br>
    Syntactic Analysis follow following steps are as follow:<br>
a)  Parsing: It helps in deciding the structure of a sentence or text in a document. It helps analyze the words in the text based on the grammar of the language.<br>
b)  Word segmentation: The segmentation of words segregates the text into small significant units.<br>
c)  Morphological segmentation: The purpose of morphological segmentation is to break words into their base form.<br>
d)  Stemming: It is the process of removing the suffix from a word to obtain its root word.<br>
e)  Lemmatization: It helps combine words using suffixes, without altering the meaning of the word.<br>

5) What is Semantic Analysis?<br>
Answer:-Semantic analysis helps make a machine understand the meaning of a text.Following are the techniques used in Semantic analysis.<br>
a) Named entity recognition: This is the process of information retrieval that helps identify entities such as the name of a person, organization, place, time, emotion, etc.<br>
b) Word sense disambiguation: It helps identify the sense of a word used in different sentences.<br>
c) Natural language generation: It is a process used by the software to convert the structured data into human spoken languages. By using NLG, organizations can automate content for custom reports<br><br>

6)  List the components of Natural Language Processing.<br>
Answer:- a) Entity extraction: Entity extraction refers to the retrieval of information such as place, person, organization, etc. by the segmentation of a sentence. It helps in the recognition of an entity in a text.<br>
b) Syntactic analysis: Syntactic analysis helps draw the specific meaning of a text.<br>
c) Pragmatic analysis: To find useful information from a text, we implement pragmatic analysis techniques.<br>
d) Morphological and lexical analysis: It helps in explaining the structure of words by analyzing them through parsing.<br>

7) What is Latent Semantic Indexing (LSI)?<br>
Answer:- Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.
